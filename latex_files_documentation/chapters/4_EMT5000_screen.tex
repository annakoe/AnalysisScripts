\section{Read trimming and Quality Filtering}
\label{sec:Bioinformatic analysis of screens with EMT5000 control library and stable cell lines}

\definecolor{my-orange}{RGB}{255,138,12}
\definecolor{my-green}{RGB}{103,215,36}  
\definecolor{my-blue}{RGB}{44,100,192}  
   
gRNA sequences integrated into the genome of FACS-sorted cells were amplified using PCR to add Illumina Nextera adapters. Libraries were sequenced on the Illumina HiSeq instrument. The resulting sequencing reads have the following general structure:

\texttt{{\color{my-green}NNNNNNN}\seqsplit{AAGTATTTCGATTTCTTGGCTTTATATATCTTGTGGAAAGGACGAAACACC}{\color{my-orange}G-N19-}\seqsplit{GTTTTAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCG}{\color{my-blue}NNNNNNN}}

The first 7 N bases are the {\color{my-green}5' barcode}, followed by the plasmid 'stuffer'.  GN19 denotes the {\color{my-orange}gRNA sequence} from the EMT5000 library, which is followed by another plasmid sequence and the last 7 N bases are the {\color{my-blue}3' barcode}. The 5' and 3' barcodes serve as unique molecular identifiers (UMIs), allowing counting of original gRNA sequences extracted from lentivirus-infected cells by removing PCR-amplification bias.

Sequences from Lane1 and Lane2 of the flow cell were combined using the unix 'cat' command. Next, the 5' barcode was extracted from the reads using cutadapt (version 1.2.1) \cite{Martin:2011va}, requiring a minimum overlap of 35 bp between the plasmid stuffer sequence and the read with a maximum error of 10 \% and a minimum barcode length of 7 bp.

\begin{small}\begin{lstlisting}
Command line parameters:
-a AAGTATTTCGATTTCTTGGCTTTATATATCTTGTGGAAAGGACGAAACACC -O 35 -m 7 

# example bash loop to run cutadapt over all fastq files 
# in the directory
for i in *.fastq.gz
do cutadapt -a AAGTATTTCGATTTCTTGGCTTTATATATCTTGTGGAAAGGACGAAACACC -O 35 -m 7 --untrimmed-output="${i%.fastq.gz}"_5bc_untrimmed.fastq.gz -o "${i%.fastq.gz}"_5bc.fastq.gz "$i";
done
\end{lstlisting}\end{small}

The 3' barcode was retrieved from the read in an analogous way:

\begin{small}\begin{lstlisting}
Command line parameters:
-g GTTTTAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCG -O 28 -m 7

# example bash loop to run cutadapt over all fastq files
# in the directory
for i in *.fastq.gz
do cutadapt -g GTTTTAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCG -O 28 -m 7 --untrimmed-output="${i%.fastq.gz}"_3bc_untrimmed.fastq.gz -o "${i%.fastq.gz}"_3bc.fastq.gz "$i";
done
\end{lstlisting}\end{small}

Finally, the gRNA sequence was extracted from the read, requiring a minimum length of 2 bp (to discard reads that contain no gRNAs and are derived from primer dimers):

\begin{small}\begin{lstlisting}
Command line parameters:
cutadapt -g AAGTATTTCGATTTCTTGGCTTTATATATCTTGTGGAAAGGACGAAACACC -a GTTTTAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCG -n 2 -m 2 -O 10

# example bash loop to run cutadapt over all fastq files 
# in the directory
for i in *.fastq.gz
do cutadapt -g AAGTATTTCGATTTCTTGGCTTTATATATCTTGTGGAAAGGACGAAACACC -a GTTTTAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCG -n 2 -m 2 -O 10 --untrimmed-output="${i%.fastq.gz}"_gRNA_untrimmed.fastq.gz -o "${i%.fastq.gz}"_gRNA.fastq.gz "$i";
done

\end{lstlisting}\end{small}

Next, the barcode and gRNA reads were quality-filtered using \verb|fastq_quality_filter| from the fastx-toolbox \cite{Hannon:Online}. Reads where any base has a Quality score of less than 20 were discarded (Example code below is for the gRNA reads.) 

\begin{small}\begin{lstlisting}
Command line parameters: -Q33 -q 20 -p 1 

#loop over all files in directory:
for i in *_gRNA.fastq; do fastq_quality_filter -Q33 -q 20 -p 1 -i "$i" -o "${i%_gRNA.fastq}"_gRNA_Q20.fastq; done
\end{lstlisting}\end{small}

Subsequently files were converted from fastq to fasta format using \verb|fastq_to_fasta| from the fastx-toolbox \cite{Hannon:Online}. 

\begin{small}\begin{lstlisting}
for i in *_gRNA_Q20.fastq;
do fastq_to_fasta -Q33 -n -i  "$i" -o "${i%gRNA_Q20.fastq}"gRNA_Q20.fasta;
done
\end{lstlisting}\end{small}

\section{Alignment to the EMT5000 library}

Guide RNA reads were next aligned back onto the indexed EMT5000 reference library using bwa (version: 0.6.2-r126) \cite{Li:2009fi}.

The indexed EMT5000 library file used as a reference for alignment and was derived from the file \verb|GN20GG_masked_autoXY_EMT_genepromoter_comprehensive_complete_noPAM_unique_strand_PAMremoved.fa| (see section \ref{Bioinf_methods: EMT5000 library}) using \verb|bwa index|:

\begin{small}\begin{lstlisting}
bwa index GN20GG_masked_autoXY_EMT_genepromoter_comprehensive_ complete_noPAM_unique_strand_PAMremoved.fa
\end{lstlisting}\end{small}

I empirically tested the following alignment parameters:

\begin{small}\begin{lstlisting}
#Command line options no mismatches, no indels:
bwa aln -n 0 -o 0 -l 5 -N -I

#Command line options 2 mismatches, no indels:
bwa aln -n 2 -o 0 -l 5 -N -I

#Command line options 3 mismatches, no indels:
bwa aln -n 3 -o 0 -l 5 -N -I

#Command line options 2 mismatches and default open gaps (1):
bwa aln -n 2 -l 5 -N -I  

#Command line options 3 mismatches and default open gaps (1):
do bwa aln -n 3 -l 5 -N -I
\end{lstlisting}\end{small}

I found that allowing 2 mismatches and 1 gap gave the best alignment (see also the table of read numbers included in the Appendix of the PhD thesis). The alignment was invoked as follows:

\begin{small}\begin{lstlisting}
for i in ../*_Q20.fasta;
do bwa aln -n 2 -l 5 -N -I EMT5000_library_reference/GN20GG_masked_autoXY_EMT_genepromoter_comprehensive_
complete _noPAM_unique_strand_PAMremoved.fa "$i" > "${i%Q20.fasta}"Q20_aligned_2mismatches1gap.sai;
done

for i in *Q20_aligned_2mismatches1gap.sai;
do bwa samse -n 10000 EMT5000_library_reference/GN20GG_masked_autoXY_EMT_genepromoter_comprehensive_
complete_noPAM_unique_strand_PAMremoved.fa "$i" "${i%Q20_aligned_2mismatches1gap.sai}"Q20.fasta > "${i%Q20_aligned_2mismatches1gap.sai}"Q20_aligned_2mismatches1gap.sam;
done
\end{lstlisting}\end{small}

Following alignment allowing 2 mismatches and 1 gap, reads that mapped uniquely to the forward strand were extracted using Samtools \cite{Li:2009kaa}:

\begin{small}\begin{lstlisting}
samtools view -F 20 -q 1 -S aligned_gRNA.sam  > gRNA_uniquely_mapped.sam
\end{lstlisting}\end{small}

To check how many different gRNAs from the library were sequenced in each sample, use:

\begin{small}\begin{lstlisting}
samtools view -F 20 -S  aligned_gRNA.sam | cut -f 3 | sort | uniq | wc -l
\end{lstlisting}\end{small}


\section{Combining the gRNA and adapter sequences in a single file}

For subsequent analysis it was necessary to construct a tab-separated file with 3 columns containing the FASTA identifier (read-ID), gRNA chr:start-end and barcode sequence for each read.

\begin{small}\begin{lstlisting}
# extract the gRNA:
samtools view -F 20 -q 1 -S aligned_gRNA.sam | awk '{print$1 ".\t" $3}'  > gRNA_uniquelymapped

# extract the FASTA identifier:
samtools view -F 20 -q 1 -S aligned_gRNA.sam | awk '{print$1 "."}' > gRNA_uniquelymapped_readID
\end{lstlisting}\end{small}

The files containing the quality-filtered 5' and 3' barcode (UMI sequence) generated above, were modified as follows (shown for 5' barcode only):

\begin{small}\begin{lstlisting}
for i in *_5bc_Q20.fasta
do cat "$i" | paste - - | awk -F ' ' '{print $1 ".\t" $3}' > "${i%_5bc_Q20.fasta}"_5bc_Q20_point.fasta;
done
\end{lstlisting}\end{small}

Next, only the barcodes associated with gRNAs that aligned uniquely were retrieved using grep:

\begin{small}\begin{lstlisting}
for i in *_5bc_Q20_point.fasta
do grep -wFf "${i%_5bc_Q20_point.fasta}"gRNA_uniquelymapped_readID "$i" > "${i%_5bc_Q20_point.fasta}"gRNA_uniquelymapped_readID_with_5bc;
done
\end{lstlisting}\end{small}

For each read, identified by its readID, the gRNA sequence and 5' and 3' barcodes were combined into a single file. The three files were joined (finding the union) using the JOIN command, which requires the files to be sorted in the following way:

\begin{small}\begin{lstlisting}
for i in *gRNA_uniquelymapped;
do awk -F "\t" '{print ">" $1 "\t" $2}' "$i"| sort -k 1b,1 > "${i%}"_sorted;
done

for i in *gRNA_uniquelymapped_readID_with_3bc;
do sort -k 1b,1 "$i" > "${i%}"_sorted;
done

for i in *gRNA_uniquelymapped_readID_with_5bc; do sort -k 1b,1 "$i" > "${i%}"_sorted;
done
\end{lstlisting}\end{small}

Next, the three files were joined as follows:

\begin{small}\begin{lstlisting}
for i in *gRNA_uniquelymapped_sorted;
do join "$i" "${i%gRNA_uniquelymapped_sorted}"gRNA_uniquelymapped_readID_with_5bc_sorted | join - "${i%gRNA_uniquelymapped_sorted}"gRNA_uniquelymapped_readID_with_3bc_sorted > "${i%gRNA_uniquelymapped_sorted}"gRNA_uniquelymapped_readID_gRNA_5bc_3bc_length14;
done
\end{lstlisting}\end{small}

This yields a file containing for each uniquely mapped read its readID, the gRNA it mapped to (chr:start-stop) and the UMI found in the read (of length exactly 14 bp).


\section[Deriving gRNA counts from UMI-barcodes without PCR error correction]{Deriving gRNA counts from UMI-barcodes \\without PCR error correction}

The gRNA counts were derived by counting the number of times each gRNA occurs together with each barcode, which acts as a unique molecular identifier (UMI). To do the gRNA counting without any error correction, the script \verb|collapse_barcodes.py| was run using a maximum edit distance of 0, i.e. not correcting any PCR errors that might have occurred in the barcode. This script can be invoked as follows:

\begin{small}\begin{lstlisting}
python collapse_barcodes.py Inputfilename 0
\end{lstlisting}\end{small}

The script accepts a tab-separated file with columns for (1) read-ID, (2) gRNA (chr:start-stop), (3) barcode and outputs two outputfiles with extension \verb|_frequency_raw| and \verb|frequency_no_orphans|. In the latter output orphan barcodes, i.e. barcodes that are only present in a single read, were removed prior to gRNA counting. Each output file has two comma-separated columns listing (1) the gRNA (chr:start-stop) and (2) the gRNA count.

The script was run over all files with the extension

\verb|_uniquelymapped_readID_gRNA_5bc_3bc_length14| as follows:

\begin{small}\begin{lstlisting}
for i in *length_14;
do python collapse_barcodes.py "$i" 0;
done
\end{lstlisting}\end{small}


\subsection{Assessing PCR error by plotting the number of reads per gRNA against number of different gRNA sequences}

To assess whether PCR error drives barcode diversity, I treated the gRNA part of the read like a barcode and plotted the correlation between number of reads and counts (see Figure 4.8. on page 134 of the PhD thesis and also section  \ref{subsec:Diagnostic_plot Counts vs reads} below). This assumes that the likelihood of introducing an error into the sequence is the same for the UMI barcodes and gRNA portions of the amplicon.

The barcode sequence was replaced with the gRNA sequence for each read to generate a tab-separated file with columns (1) readID (2) gRNA chr:start-stop (3) 'pseudo-barcode'(gRNA sequence) as follows:

\begin{small}\begin{lstlisting}
#get gRNA sequence 
cat Sample_gRNA_Q20.fasta | paste - - | awk -F ' ' '{print $1 ".\t" $3}' | sort > Sample_gRNA_Q20_point

#get the read ID
awk -F '\t' '{print $1}' Sample_gRNA_5bc_3bc_length14 | sort > Sample_gRNA_5bc_3bc_length14_read_ID

#get gRNA sequence for each readID
grep -wFf Sample_gRNA_5bc_3bc_length14_read_ID Sample_gRNA_Q20_point > Sample_gRNA_Q20_point_uniquely_mapped

#sort the previously generate file containing [0] readID, [1] gRNA chr:start-stop, [2] UMI of 5' and 3' barcode
sort -k 1b,1 Sample_gRNA_uniquelymapped_readID_gRNA_5bc_3bc_length14 > Sample_gRNA_uniquelymapped_
readID_gRNA_5bc_3bc_length14_sorted

#sort the gRNA sequence file
sort -k 1b,1 Sample_gRNA_Q20_point_uniquely_mapped > Sample_gRNA_Q20_point_uniquely_mapped_sorted

#join the two files on readID
join Sample_gRNA_Q20_aligned_2mismatches1gap_uniquelymapped_
readID_gRNA_5bc_3bc_length14_sorted Sample_gRNA_Q20_point_uniquely_mapped_sorted | awk -F ' ' '{print $1 "\t" $2 "\t" $4}' > Sample_gRNA_Q20_aligned_2mismatches1gap_uniquelymapped_
readID_gRNA_instead_of_barcode
\end{lstlisting}\end{small}

This file was then run through \verb|collapse_barcodes.py| as above and results were plotted as described in section \ref{subsec:Diagnostic_plot Counts vs reads}.

\begin{small}\begin{lstlisting}
python collapse_barcodes.py Sample_gRNA_Q20_aligned_2mismatches1gap_
uniquelymapped_readID_gRNA_instead_of_barcode 0
\end{lstlisting}\end{small}

\section{Deriving gRNA counts from UMI-barcodes with naive PCR error correction}

The script \verb|collapse_barcodes.py| was run using a maximum edit distance of 4. 

\begin{small}\begin{lstlisting}
python collapse_barcodes.py Samplefilename 4
\end{lstlisting}\end{small}

This means that before counting how many different barcodes are associated with each gRNA, the barcodes are collapsed into groups. Barcodes are first ranked in decreasing order based on the number of reads harbouring its sequence. The barcode with the most reads forms the first group. If the second-ranked barcode is within 4 edit-distances of this barcode it will be assumed to have originated by PCR error and will be added to the group. If the barcode differs from the group by greater than 4 edits, it will form its own group and so on. The number of groups per gRNA is the count after error correction. This reflects the number of original gRNA-barcode combinations.


The script was run over all files with the extension 

\verb|_uniquelymapped_readID_gRNA_5bc_3bc_length14| as follows:

\begin{small}\begin{lstlisting}
for i in *length_14;
do python collapse_barcodes.py "$i" 4;
done
\end{lstlisting}\end{small}


\section{Bayesian PCR error correction of barcoded sequencing data }

A Bayesian error correction script was written by James E. Barrett to infer gRNA counts from the UMI data. The model takes into account the fact that the 14 bp UMI consists of a 5' and 3' barcode that was attached to the gRNA amplicon during and initial round off PCR amplification during the sequencing library prep. The model infers the most likely number of initial gRNA-barcode data given the barcode sequences observed in the sequencing sample.

This Bayesian model takes as input the number of reads associated with each gRNA-UMI combination (without PCR error correction). I calculated these using the script make-csv-4Bayes.py. The script was run over all samples as follows:

\begin{small}\begin{lstlisting}
for i in *length14; do python ../make_csv_4Bayes.py "$i"; done
\end{lstlisting}\end{small}

This script again takes the tab-separated three column file that lists (1) read ID, (2) gRNA (chr:start-end) and (3) barcode consisting of 5' UMI and 3' UMI fused together as input. The output is a csv file with three columns containing (1) gRNA (chr:start-end), (2) barcode consisting of 5' UMI and 3' UMI fused together and (3) number of reads associated with each barcode. The outputfile has the extension \verb|_barcode_readcounts.csv| and is  fed into a Bayesian error correction script described below.

\subsection{Bayesian PCR error correction of barcoded sequencing count data script (by James E. Barrett)}
\label{sec:Bayesian-methods}

This script and documentation was kindly contributed by James E. Barrett. 

The Bayesian model infers the number of unique original barcoded gRNA molecules from noise-corrupted count data. The model estimates a corrected read count, which may be interpreted as a proxy for the original noise-free number of unique barcodes associated with a particular gRNA. 

\subsubsection{Model definition}
For each gRNA we observe $N$ barcode pairs denoted by $(\vecy_{i}^1,\vecy_{i}^2)$ where the superscript denotes the first and second barcodes and $i=1,\ldots,N$. Elements of the $d$-dimensional vector $\vecy_{i}^{\eta}\in\{\verb+T+,\verb+C+,\verb+G+,\verb+A+\}^d$ where $\eta=[1,2]$. The number of corresponding sequencing reads is denoted by $\sigma_{i}\in\mathbb{Z}_+$. 

The model assumes that there exist $Q$ \emph{latent barcodes} $\vecx_1^{\eta},\ldots,\vecx_Q^{\eta}$ from which the observed barcodes are generated in a noise corrupting stochastic process (PCR amplification errors and random barcode switching). The model further assumes that for each pair $(\vecy_i^1,\vecy_i^2)$ only one of the observed barcodes is written in terms of the latent barcode via
\begin{equation}
\vecy_i^{\eta} = \sum_{q=1}^Q w_{iq}^{\eta}\theta(\vecx_{q}^{\eta})\quad\text{subject to}\quad w_{iq}^{\eta}\in[0,1]\quad\text{and}\quad\sum_{q,\eta} w_{iq}^{\eta} = 1.
\end{equation}
There is therefore only one non-zero value of $[\vecw_i^1,\vecw_i^2]$ that indicates which latent barcode the observed pair is associated with. The function $\theta$ represents a noise corrupting stochastic process where the status of each nucleotide site may be changed randomly with probability $\beta\in[0,1/2]$. We can therefore write
\begin{equation}
p(y_{i\mu}^{\eta}|x_{q\mu}^{\eta},\beta) = \left\{
\begin{array}{lr}
(1-\beta)\delta_{y_{i\mu}^{\eta}x_{q\mu}^{\eta}} + \beta (1-\delta_{y_{i\mu}^{\eta}x_{q\mu}^{\eta}})&\quad\text{if $w_{iq}^{\eta}=1$}\\
0&\quad\text{otherwise}\\
\end{array}
\right.
\end{equation}
for $\mu=1,\ldots,d$. We denote the collections of $\vecx_{q}^{\eta}$, $\vecy_i^{\eta}$ and $\vecw_i^{\eta}$ by $\matX$, $\matY$, and $\matW$ respectively. The posterior is
\begin{equation}
p(\matX,\matW|\matY,\sv,\beta) \propto p(\matY|\matX,\matW,\sv,\beta)p(\matX)p(\matW)
\end{equation}
with
\begin{align}
p(\matY|\matX,\matW,\sv,\beta) &=\prod_{i}\left[\sum_{q,\eta}w_{iq}^{\eta} p(\vecy_i^{\eta}|\vecx_q^{\eta},\beta)\right]^{\sigma_i}.
\label{eq:likelihood}
\end{align}
Maximum entropy priors for $\matX$ and $\matW$ are uniform distributions so $p(\matX)$ and $p(\matW)$ are constant.

\subsubsection{Inference of model parameters}

The Maximum A Posteriori (MAP) solution of $\matW$ is denoted by $\matW^*$. Since only one element of $[\vecw_i^1,\vecw^2_i]$ is non-zero the expression (\ref{eq:likelihood}) is maximised by selecting $\text{argmax}_{q,\eta} p(\vecy_i^{\eta}|\vecx_q^{\eta},\beta)$ as the non-zero element.

To find the MAP solution for nucleotide $\mu$ of the latent barcode indexed by $(q,\eta)$ we consider all observed barcodes that generated from it (as defined by $\matW$). If we let $n_1$ and $n_0$ denote the total number of matches and mismatches respectively between that latent barcode and the associated observed barcodes, then the corresponding data likelihood is $(1-\beta)^{n^1_{q\mu}}\beta^{n^0_{q\mu}}$. This will be maximised if the number of matches is maximised. This is achieved selecting the most common observed nucleotide as the value for the latent nucleotide (while taking into account multiple counts).

If we let $N_1$ and $N_0$ denote the total number of matches and mismatches respectively across all of the latent barcodes and observed data then we can write 
\begin{equation}
\log p(\matY|\matX,\matW,\beta) = N_1 \log(1-\beta) + N_0\log\beta.
\end{equation}
It is straightforward to show that the MAP estimate for beta is
\begin{equation}
\beta = \frac{N_0}{N_0+N_1}.
\end{equation}


The optimisation subroutine is initialised as follows:

Cluster into $Q$ groups based on the \emph{Hamming distance} between two barcodes (the Hamming distance is equivalent to the \emph{edit distance}):
\begin{equation}
h(\vecy_i,\vecy_j) = \frac{1}{d}\sum_{\mu=1}^{d}\delta_{(1-y_{i\mu})y_{j\mu}}.
\end{equation}


The corrected read counts are inferred as follows:

For a given value of $Q$ we denote the value of the likelihood (\ref{eq:likelihood}) at the MAP parameter estimate by
\begin{equation}
L(Q) = p(\matY|\matX^*,\matW^*,\beta^*).
\end{equation}
The \emph{Bayes information criterion} (BIC) score is defined by
\begin{equation}
\text{BIC}(Q) = -2\log L(Q) + 2dQ\log N
\end{equation}
where $2dQ$ is the number of free parameters in the model. The \emph{corrected read count} is defined by
\begin{equation}
Q^* = \text{argmin}_Q \text{BIC}(Q).
\end{equation}


\subsubsection{Bayesian error correction script: The Code}

The analysis is  performed in R:

\begin{small}\begin{lstlisting}
library(reshape2)

### Load and prepare a data file

# Length of barcode
D <- 7
# Load up one of the data files (needs to be in the current directory)
data <- read.csv("Samplename_length14_barcode_readcounts.csv",header=FALSE)
# vector of all the unique gRNA names
gRNA <- unique(data$V1)
# Total number of unique gRNAs
G <- length(gRNA)

### Generate datasets of barcodes

# Preallocate a list structure to hold the barcode datasets
Y <- vector('list',G)

# This loop goes through each gRNA, pulls out all the associated barcodes and puts them in a character matrix
for(mu in 1:G){
   ind <- which(data[[1]]==gRNA[mu])
   N <- length(ind)
   # Converts into character matrix (not the most elegant way...)
   Y[[mu]] <- matrix(as.vector(melt(lapply(as.character(data[[2]][ind]),strsplit,split=""))$value),nrow=N,ncol=2*D,byrow=TRUE)
}

### Fit model for each gRNA

# Preallocate a list of model results
res <- vector('list',G)

# Loop through gRNAs, for each one fit a model and get the corrected read count
# This can be parallelised for speed
for(mu in 1:G){
   # Begin tryCatch (catches any errors instead of stopping the loop)
   tryCatch({
      # Indices for barcodes matched that the current gRNA
      ind <- which(data[[1]]==gRNA[mu])
      # Vector of read counts
      counts <- data[[3]][ind]
      # Fit the model
      res[[mu]] <- fit_model(Y[[mu]], counts)
   }, error=function(e) NULL) #End tryCatch
} # End loop over gRNAs
\end{lstlisting}\end{small}

This analysis calls functions stored in the R scripts \verb|fit_model.R|, \verb|LL.R| and \verb|hamming.R|.
A csv file of counts per gRNA for each sample (\verb|bayesian_corrected.csv|) was then exported.

\section{Diagnostic plot: Number of UMI-corrected counts versus number of reads per gRNA}
\label{subsec:Diagnostic_plot Counts vs reads}

\subsection{Calculating the number of reads per gRNA}

To calculate the number of reads per gRNA for each sample, I wrote the script \verb|reads_per_gRNA.py|. This takes a 3 column tab-separated inputfile with the following columns: (1) read ID (2) gRNA chr:start-stop (3) 14 nt barcode and outputs a csv file with two columns: (1) gRNA chr:start-stop , (2) number of reads. The script can be invoked as follows:

\begin{small}\begin{lstlisting}
for i in *length14; do python ./reads_per_gRNA.py "$i"; done
\end{lstlisting}\end{small}

\subsection{Wrapping gRNA counts of all samples into a table}

While the Bayesian model outputs a csv file containing the counts per gRNA for each sample directly, the output of the script \verb|collapse-barcodes.py| (used to count gRNAs without error correction or to perform a naive PCR error correction) outputs one table per sample. This data can be merged into a single table listing for each gRNA the count in each sample using the script \verb|make_table_from_counts.py|. This script also adds information about which gene is targeted by each gRNA. The script takes a variable number of inputfiles to wrap into a table:

\begin{small}\begin{lstlisting}
python makeTable_from_counts.py INPUTFILE1 INPUTFILE2 ... INPUTFILEn
\end{lstlisting}\end{small}

This was used to generate the tables \verb|Dataframe_allsamples_readcounts.txt|  \verb||  \verb|| 

\subsection{Generating the plots of counts versus number of reads for each gRNA}

The number of reads per gRNA were plotted against the counts per gRNA, derived either without error correction, with naive PCR error correction or Bayesian PCR error correction (as described above), using the script \verb|plot_counts_vs_number_of_reads.py|. Samplesheets can be found in the folder ``samplefiles".

\begin{small}\begin{lstlisting}
python plot_counts_vs_number_of_reads.py [Dataframe-Counts] [Dataframe-NumberOfReads] [Samplesheet]
\end{lstlisting}\end{small}

\begin{small}\begin{lstlisting}
# no PCR error correction
plot_counts_vs_number_of_reads.py Dataframe_allsamples_no_errors.txt Dataframe_allsamples_readcounts.txt samplefile.txt

# naive PCR error correction (4 mismatches)
plot_counts_vs_number_of_reads.py Dataframe_allsamples.txt Dataframe_allsamples_readcounts.txt samplefile.txt

# Bayesian error correction
plot_counts_vs_number_of_reads.py bayesian_corrected.csv Dataframe_allsamples_readcounts.txt samplefile.txt
\end{lstlisting}\end{small}

This script was used to generate the plots in Figure 4.9 and Figure 4.10 of the PhD thesis. 

\section{Diagnostic plot: Counts versus number of sorted cells}

This script accepts three user-supplied arguments, a dataframe of gRNA counts (c), a dataframe of numbers of sorted cells per sample (n), and a samplesheet (s) and returns a scatterplot of sorted cells versus counts with one data point per sample in the samplesheet. It is further hardcoded to color the dots according to whether two or three initial cycles of barcoding PCR were used to attach unique molecular identifiers to gRNA sequences before amplification and sequencing. The samplesheets can be found in the folder \verb|samplefiles| and the file recording the number of sorted cells is in the folder \verb|additional-files|. The script was invoked as follows:

\begin{small}\begin{lstlisting}
python cellnumber_vs_counts.py -c bayesian_corrected.csv -n Number_of_sorted_cells.csv  -s samplefile_all.txt 
\end{lstlisting}\end{small}

This script was used to produce the graph in Figure 4.11 on page 134 of the PhD thesis.


\section{Enrichment analysis using DESeq2}

Enrichment analysis was carried out using the DESeq2 package \cite{Love:2014eo}.

\subsection{Preparing Bayesian error correction output for DESeq2}

DESeq2 requires a list of counts per gRNA for each experiment to be analysed. The data for each experiment were extracted from the Bayesian analysis output file \verb|bayesian_corrected.csv|. gRNAs  with a  lot of missing data where 3/4 of the counts in a given experiment are 0 (or NA) are removed before enrichment analysis using the script \verb|make_input_4_DESeq.py| The samplesheets can be found in the folder \verb|samplefiles|. 

\begin{small}\begin{lstlisting}
python make_input_4_DESeq.py -i bayesian_corrected.csv -s Samplefile_Batch8.txt
\end{lstlisting}\end{small}

Using the above example, the script outputs a file named \verb|Batch8_p300_counts.csv|.

\subsection{Running DESeq2}
This analysis was conducted using the script \verb|DESeq2_script.R|. An example of how this script is run over the example file for experiment \verb|Batch8_p300|  is shown below. DESeq2 further requires a file containing experimental information, specifying for each sample whether it belongs to the treatment or control group. These files can be found in the folder \verb|additional_files/ColData_forDESeq2|.

\begin{small}\begin{lstlisting}
./DESeq2_script.R -c path_to/DeSeq2/Inputfiles/Batch8_p300_counts.csv -e path_to/additional_files/ColData_forDESeq2/Batch8_DeSeq2_ColData -o 'Batch8_p300_DESeq2_table.csv'
\end{lstlisting}\end{small}

This outputs a csv file with the samplename and the extension \verb|_DESeq2_table.csv|.

\subsection{Visualizing enrichment}
Log2 Fold Change between samples and controls for each gRNA was calculated using DESeq2 as described above. Log2Fold Change values were extracted from the output of DESeq2 (filename is \verb|Batch8_p300_DESeq2_table.csv| for this particular example) and plotted along the chromosome for each gene in the library. To extract the relevant data and generate the plots I wrote the python script \verb|Plot_Log2FC_along_chr.py|. This script requires as input the additional files \verb|EMT5000_library_regions.bed|, and \verb|EMT5000_library_TSS.txt| in order to plot enrichment for each gRNA with respect to the transcriptional start site of the gene from the library. Both files can can be found in the folder \verb|additional_files|. The script can be invoked as follows:

\begin{small}\begin{lstlisting}
python Plot_Log2FC_along_chr.py -c Batch8_p300_DESeq2_table.csv -l EMT5000_library_regions.bed -t EMT5000_library_TSS.txt
\end{lstlisting}\end{small}

This script was used to generate the plots in Figure 4.12 on page 136 of the PhD thesis.

\subsection{Correlation of Log2Fold enrichment scores from DESeq2 between experiments}

The script \verb|plot_LogFC_vs_LogFC.py| performs all-by-all comparison of Log2Fold Change per gRNA across an arbitrary number of inputfiles. The script can be invoked as follows:

\begin{small}\begin{lstlisting}
python plot_LogFC_vs_LogFC.py  [list of DESeq output dataframes to be compared]
\end{lstlisting}\end{small}

This script was used to generate the plots in Figure 4.13 on page 138 of the PhD thesis.

\subsection{Identification of candidate gRNAs using ranking with desirability functions}
\label{sec:ranking-methods}
The Log2Fold Change and Log2Fold Change standard error were extracted from the DESeq2 output in python (using ipython notebook interactively) as follows:

\begin{small}\begin{lstlisting}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import collections as coll
import re
import pylab
import pybedtools
%gui 
%matplotlib inline

def load_into_df(arg):
    user_input = pd.DataFrame.from_csv(arg, header=0, sep=',', index_col=0)
    return user_input

def set_DESEq2_outliers_to_0_and_wrap_into_df(list_of_dfs, names_of_dfs):
    dict_for_df = {} 
    for index, df in enumerate(list_of_dfs): #iterate over the dataframes
        outliers = df.loc[np.isnan(df['pvalue'])] #make a dataframe 'outliers' that holds all rows where pvalue is NA, i.e DESeq2 has detected an outlier
        outliers['log2FoldChange']=0 #if pvalue is NA set L2FC to 0
        outliers_removed = df.loc[~np.isnan(df['pvalue'])] #make new df only containing rows where pvalue is NOT NaN
        df_combined = pd.concat([outliers, outliers_removed])   #combine the two dataframes
        dict_for_df[names_of_dfs[index] + '_log2FoldChange'] = (df_combined["log2FoldChange"])
        dict_for_df[names_of_dfs[index] + '_LfcSE'] = (df_combined["lfcSE"]) #add the columns holding L2FC of this dataframe to a dict
    my_df=pd.DataFrame(dict_for_df) #take entries from a list into a df
    return my_df

Batch8_p300 = load_into_df('path2/DESeq2_output_tables/Batch8_p300_DESeq2_table.csv')
Batch4_p300 = load_into_df('path2//DESeq2_output_tables/Batch4_p300_DESeq2_table.csv')
BatchSS0209_p300 = load_into_df('path2/DESeq2_output_tables/BatchSS0209_p300_DESeq2_table.csv')
BatchSS2608_p300 = load_into_df('path2/DESeq2_output_tables/BatchSS2608_p300_DESeq2_table.csv')
BatchSS0209_Set7 = load_into_df('path2/DESeq2_output_tables/BatchSS0209_Set7_DESeq2_table.csv')
BatchSS2608_Set7 = load_into_df('path2/DESeq2_output_tables/BatchSS2608_Set7_DESeq2_table.csv')
Batch5_Set7 = load_into_df('path2/DESeq2_output_tables/Batch5_Set7_DESeq2_table.csv')
Batch3_Set7 = load_into_df('path2/DESeq2_output_tables/Batch3_Set7_DESeq2_table.csv')

list_p300= [Batch8_p300, Batch4_p300, BatchSS0209_p300, BatchSS2608_p300]
names_p300 = ['Batch8_p300', 'Batch4_p300', 'BatchSS0209_p300', 'BatchSS2608_p300']

list_Set7 = [Batch3_Set7, Batch5_Set7, BatchSS0209_Set7, BatchSS2608_Set7]
names_Set7 = ['Batch3_Set7', 'Batch5_Set7', 'BatchSS0209_Set7', 'BatchSS2608_Set7']

p300s_L2FC = set_DESEq2_outliers_to_0_and_wrap_into_df(list_p300, names_p300)
p300s_L2FC.to_csv('p300s_DESeq_L2FC_NApvalue2zero.csv', sep=',')

Set7_L2FC = set_DESEq2_outliers_to_0_and_wrap_into_df(list_Set7, names_Set7)
Set7_L2FC.to_csv('Set7s_DESeq_L2FC_NApvalue2zero.csv', sep=',')
\end{lstlisting}\end{small}

For each gRNA where DESeq2 had detected outliers (and set the p-value to NA in the output) Log2Fold Change values were set to 0 before the next step, i.e. ranking of gRNAs.

The script \verb|Desirability.R| was used to rank gRNAs based on large positive Log2FC and small Log2FC standard error. A weighted average is calculated and Log2FC is given four times the weight of its standard error during this ranking:

\begin{small}\begin{lstlisting}
./Desirability.R -f p300s_DESeq_L2FC_NApvalue2zero.csv -w 4 -e 1
\end{lstlisting}\end{small}

The script outputs a ranked list of candidate gRNAs, ranked based on the calculated overall desirability  (here \verb|p300_candidates_4xL2FC_1xLfcSE.csv| as well as plots showing Desirabilities across all gRNAs as well as histograms for Log2Fold Changes and associated standard errors. These are shown in Figure 4.14 on page 139 of the PhD thesis.

The top 10 candidates were extracted from the list of gRNAs ranked by their Desirability score for use in the validation experiments. The sequences were extracted for cloning into the gRNA vector as follows:

\begin{small}\begin{lstlisting}
head -11 p300_candidates.csv | sed 1d | awk -F '",' '{print $1}' | awk -F '"' '{print $2}' > p300_top10.bed

grep -A1 -wf p300_top10.bed /path2/GN20GG_masked_autoXY_EMT_genepromoter_comprehensive_complete_
noPAM_unique_strand_PAMremoved.fa > p300_top10.fa
\end{lstlisting}\end{small}


For the candidate gRNAs the Bayesian-corrected counts in samples and controls were plotted using the custom script \verb|Plot_candidates.R|. For this, the counts for each gRNA for all samples from a given experiment were first extracted from the output of the Bayesian error correction script (see section \ref{sec:Bayesian-methods}) using the script 
\verb|extract_all_counts_per_experiment_from_bayes.py|, which was invoked as follows:

\begin{small}\begin{lstlisting}
python extract_all_counts_per_experiment_from_bayes.py
\end{lstlisting}\end{small}

This produces, for each experiment a file with extension \verb|_all-counts.csv|. This file was edited to replace all occurrences of NA with 0 using the script \newline
\verb|Print_counts_missing_as_0.R|. The file containing the output of the Bayesian error correction script for all experiments using the dCas9-p300 chromatin modifier is shown as an example: 

\begin{small}\begin{lstlisting}
./Print_counts_missing_as_0.R -f All_p300_all-counts.csv
\end{lstlisting}\end{small}

For this particular example, this script outputs a file named \newline
\verb|All_p300_all-counts_missing_as_0.csv|, which contains for all experiments using the dCas9-p300 chromatin modifier the counts per gRNA following Bayesian error correction for all samples and controls with NAs replaced by 0. This file together with the ranked list of candidates (from section \ref{sec:ranking-methods}) was fed to the script \verb|Print_counts_missing_as_0.R| as follows:

\begin{small}\begin{lstlisting}
./Plot_candidates.R -f p300_candidates_4xL2FC_1xLfcSE.csv -c All_p300_all-counts_missing_as_0.csv
\end{lstlisting}\end{small}

This produced the plots in Figure 4.15 and 4.16 on page 140 and 141 of the PhD thesis.